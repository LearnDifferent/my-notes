[toc]

本文主要摘抄自：[JavaGuide](https://javaguide.cn/)

# 集合

## 集合基本概念

Java 集合， 也叫作容器，主要是由两大接口派生而来：一个是 `Collection` 接口，主要用于存放单一元素；另一个是 `Map` 接口，主要用于存放键值对。

对于 `Collection` 接口，下面又有三个主要的子接口：`List`、`Set` 和 `Queue`。

## Collection 基本数据结构

### List

List 接口：

- `Arraylist`：`Object[]` 数组
- `Vector`：`Object[]` 数组
- `LinkedList`： 双向链表

---

***ArrayList 和 Vector 的区别？***

- `ArrayList` 是 `List` 的主要实现类，底层使用 `Object[]`存储，适用于频繁的查找工作，线程不安全
- `Vector` 是 `List` 的古老实现类，底层使用`Object[]` 存储，线程安全的。

---

***ArrayList 与 LinkedList 共同点？***

**是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全

**底层数据结构：** `ArrayList` 底层使用的是 **`Object` 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环）

**插入和删除是否受元素位置的影响：**

- <u>`ArrayList` 采用数组存储</u>，所以插入和删除元素的时间复杂度受元素位置的影响。
- 比如：执行 `add(E e)` 方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。
- 但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
- <u>`LinkedList` 采用链表存储</u>，所以，如果是在头尾插入或者删除元素不受元素位置的影响（`add(E e)`、`addFirst(E e)`、`addLast(E e)`、`removeFirst()` 、 `removeLast()`），时间复杂度为 O(1)
- 如果是要在指定位置 `i` 插入和删除元素的话（`add(int index, E element)`，`remove(Object o)`）， 时间复杂度为 O(n) ，因为需要先移动到指定位置再插入。
- **是否支持快速随机访问：**`LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。

 **内存空间占用：**`ArrayList` 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）

### Set

Set 接口：

- `HashSet` (无序，唯一): 
	- 基于 `HashMap` 实现的，底层采用 `HashMap` 来保存元素
- `LinkedHashSet`: 
	- `LinkedHashSet` 是 `HashSet` 的子类，并且其内部是通过 `LinkedHashMap` 来实现的。
	- 有点类似于 `LinkedHashMap` 其内部是基于 `HashMap` 实现一样，不过还是有一点点区别的
- `TreeSet` (有序，唯一): 
	- 红黑树(自平衡的排序二叉树)

---

***HashSet、LinkedHashSet 和 TreeSet 三者的异同***

- `HashSet`、`LinkedHashSet` 和 `TreeSet` 都是 `Set` 接口的实现类，都能保证元素唯一，并且都不是线程安全的。
- `HashSet`、`LinkedHashSet` 和 `TreeSet` 的主要区别在于底层数据结构不同。
  - `HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。
  - `LinkedHashSet` 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。
  - `TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。

- 底层数据结构不同又导致这三者的应用场景不同。
  - `HashSet` 用于不需要保证元素插入和取出顺序的场景
  - `LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景
  - `TreeSet` 用于支持对元素自定义排序规则的场景

---

***`comparable` 和 `Comparator` 的区别***

`comparable` 接口实际上是出自 `java.lang` 包，它有一个 `compareTo(Object obj)` 方法用来排序

`comparator`接口实际上是出自 `java.util` 包它有一个 `compare(Object obj1, Object obj2)`方法用来排序

一般我们需要对一个集合使用自定义排序时，我们就要重写`compareTo()`方法或`compare()`方法，当我们需要对某一个集合实现两种排序方式，比如一个 song 对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写`compareTo()`方法和使用自制的`Comparator`方法或者以两个 Comparator 来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 `Collections.sort()`.

**Comparator 定制排序**

```java
        ArrayList<Integer> arrayList = new ArrayList<Integer>();
        arrayList.add(-1);
        arrayList.add(3);
        arrayList.add(3);
        arrayList.add(-5);
        arrayList.add(7);
        arrayList.add(4);
        arrayList.add(-9);
        arrayList.add(-7);
        System.out.println("原始数组:");
        System.out.println(arrayList);
        // void reverse(List list)：反转
        Collections.reverse(arrayList);
        System.out.println("Collections.reverse(arrayList):");
        System.out.println(arrayList);

        // void sort(List list),按自然排序的升序排序
        Collections.sort(arrayList);
        System.out.println("Collections.sort(arrayList):");
        System.out.println(arrayList);
        // 定制排序的用法
        Collections.sort(arrayList, new Comparator<Integer>() {

            @Override
            public int compare(Integer o1, Integer o2) {
                return o2.compareTo(o1);
            }
        });
        System.out.println("定制排序后：");
        System.out.println(arrayList);
```

Output:

```text
原始数组:
[-1, 3, 3, -5, 7, 4, -9, -7]
Collections.reverse(arrayList):
[-7, -9, 4, 7, -5, 3, 3, -1]
Collections.sort(arrayList):
[-9, -7, -5, -1, 3, 3, 4, 7]
定制排序后：
[7, 4, 3, 3, -1, -5, -7, -9]
```

**重写 compareTo 方法实现按年龄来排序**

```java
// person对象没有实现Comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列
// 前面一个例子的String类已经默认实现了Comparable接口，详细可以查看String类的API文档，另外其他
// 像Integer类等都已经实现了Comparable接口，所以不需要另外实现了
public  class Person implements Comparable<Person> {
    private String name;
    private int age;

    public Person(String name, int age) {
        super();
        this.name = name;
        this.age = age;
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public int getAge() {
        return age;
    }

    public void setAge(int age) {
        this.age = age;
    }

    /**
     * T重写compareTo方法实现按年龄来排序
     */
    @Override
    public int compareTo(Person o) {
        if (this.age > o.getAge()) {
            return 1;
        }
        if (this.age < o.getAge()) {
            return -1;
        }
        return 0;
    }
}
    public static void main(String[] args) {
        TreeMap<Person, String> pdata = new TreeMap<Person, String>();
        pdata.put(new Person("张三", 30), "zhangsan");
        pdata.put(new Person("李四", 20), "lisi");
        pdata.put(new Person("王五", 10), "wangwu");
        pdata.put(new Person("小红", 5), "xiaohong");
        // 得到key的值的同时得到key所对应的值
        Set<Person> keys = pdata.keySet();
        for (Person key : keys) {
            System.out.println(key.getAge() + "-" + key.getName());

        }
    }
```

Output：

```text
5-小红
10-王五
20-李四
30-张三
```

---

***无序性和不可重复性的含义是什么***

- 无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。
- 不可重复性是指添加的元素，按照 `equals()` 判断时 ，返回 false，需要同时重写 `equals()` 方法和 `hashCode()` 方法。

### Queue 

Queue 接口：

- `PriorityQueue`: `Object[]` 数组来实现二叉堆
- `ArrayQueue`: `Object[]` 数组 + 双指针

---

***Queue 与 Deque 的区别***

<u>`Queue` 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 **先进先出（FIFO）** 规则</u>。

`Queue` 扩展了 `Collection` 的接口，根据 **因为容量问题而导致操作失败后处理方式的不同** 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。

| `Queue` 接口 | 抛出异常  | 返回特殊值 |
| ------------ | --------- | ---------- |
| 插入队尾     | add(E e)  | offer(E e) |
| 删除队首     | remove()  | poll()     |
| 查询队首元素 | element() | peek()     |

<u>`Deque` 是双端队列，在队列的两端均可以插入或删除元素</u>。

`Deque` 扩展了 `Queue` 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类：

| `Deque` 接口 | 抛出异常      | 返回特殊值      |
| ------------ | ------------- | --------------- |
| 插入队首     | addFirst(E e) | offerFirst(E e) |
| 插入队尾     | addLast(E e)  | offerLast(E e)  |
| 删除队首     | removeFirst() | pollFirst()     |
| 删除队尾     | removeLast()  | pollLast()      |
| 查询队首元素 | getFirst()    | peekFirst()     |
| 查询队尾元素 | getLast()     | peekLast()      |

事实上，`Deque` 还提供有 `push()` 和 `pop()` 等其他方法，可用于模拟栈。

---

***ArrayDeque 与 LinkedList 的区别***

`ArrayDeque` 和 `LinkedList` 都实现了 `Deque` 接口，两者都具有队列的功能，但两者有什么区别呢？

- `ArrayDeque` 是基于可变长的数组和双指针来实现，而 `LinkedList` 则通过链表来实现。
- `ArrayDeque` 不支持存储 `NULL` 数据，但 `LinkedList` 支持。
- `ArrayDeque` 是在 JDK1.6 才被引入的，而`LinkedList` 早在 JDK1.2 时就已经存在。
- `ArrayDeque` 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 `LinkedList` 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。

从性能的角度上，选用 `ArrayDeque` 来实现队列要比 `LinkedList` 更好。此外，`ArrayDeque` 也可以用于实现栈。

---

***PriorityQueue***

`PriorityQueue` 是在 JDK1.5 中被引入的, 其与 `Queue` 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。

- `PriorityQueue` 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据
- `PriorityQueue` 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。
- `PriorityQueue` 是非线程安全的，且不支持存储 `NULL` 和 `non-comparable` 的对象。
- `PriorityQueue` 默认是小顶堆，但可以接收一个 `Comparator` 作为构造参数，从而来自定义元素优先级的先后。

`PriorityQueue` 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第K大的数、带权图的遍历等，所以需要会熟练使用才行。

## 遍历 Collection 的迭代器

### Iterator 和 Iterable

`Iterator` 是一个接口，有 2 个抽象方法：

1. `hasNext()` 来判断是否还有数据可以访问

2. `next()` 用来访问集合的下一个数据

集合并不是直接实现 `Iterator` 接口，而是通过实现 `Iterable` 接口，来返回当前集合实现了 `Iterator` 接口的迭代器实例。

这是为了每次都能返回新的迭代器，遍历数据时互不影响：

- 如果没有返回新的迭代器，而是只有一个迭代器
- 那么遍历完 1 次数据后，第 2 次就没有数据可以遍历了，所以选择每次都返回一个新的迭代器。

### fail-fast 机制

fail-fast 机制：

- 为了保证在迭代时，不会出现集合突然被添加或删除元素

- 迭代器中会保存一个 int 数值 modCount，用来记录集合增删操作的次数

- 在迭代时，会对比 modCount 是否和当初的数值一致

- 如果不一致，就抛出 `ConcurrentModificationException`，也就是 fail-fast

因为 for-each 循环的底层就是迭代器，所以在 for-each 中直接对集合进行增删操作，也可能会抛出异常。

### CopyOnWrite

作用：CopyOnWriteList 可以在遍历数据的同时，对集合进行增删操作。

原理：

- 为了避免增删元素时，影响到迭代器，CopyOnWrite 集合在增删元素时，就不会在原数组上操作，
- 而是会新建一个数组，然后将原数组的元素挨个复制过去，再在新数组上增删元素，这样就不会影响之前的迭代器。
- 而且增删操作还加上了 `synchronized` 锁，所以是线程安全的。
- 不过，读取的操作是没有加锁的，这是为了提高性能。

优点：

- CopyOnWrite 只会复制数据的引用，不会复制数据本身。所以在获取迭代器，或者说获取数据时，速度很快
- 而且增删操作上了锁，所以适合并发场景
- 保障了迭代器的独立性和隔离性（读写分离）

缺点：

- 因为每次增删操作，都会复制数据，所以集合在增删操作时，性能比较低。
- 而且占用内存大，容易触发 GC。
- 读操作没有上锁，所以数据可能不是最新的，数据可能出现不一致的问题

适用范围：适用于读多写少，且数据量不大的情况。比如，配置和商品类别这种变更很少的数据。

## Map

`HashMap`：

- 数组 + 链表，数组是 `HashMap` 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）
- HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，以此来判断该元素应该存放的位置
	- 如果当前位置存在元素的话，就判断两个元素之间的 hash 值和 key 是否相同
	- 如果相同的话，直接覆盖，不相同就通过拉链法解决冲突
	- JDK1.8 之后，如果链表长度大于阈值（默认为 8）时，会将链表转化为红黑树，以减少搜索时间。
- `HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个

`LinkedHashMap`：

- 在 `HashMap` 的基础上，添加了双向链表
- `LinkedHashMap` 继承自 `HashMap`，所以它的底层仍然是基于拉链式散列结构，即由数组和链表或红黑树组成。
- 另外，`LinkedHashMap` 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。
- 同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。

`ConcurrentHashMap`：

- 底层采用 **分段的数组 + 链表** 实现
- 在 JDK1.7 的时候，`ConcurrentHashMap` 将数据分为不同的 `Segment`，每一把锁只锁 `Segment` 中数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率
- JDK1.8 的时候已经摒弃了 `Segment` 的概念
	- 直接用 `Node` 数组+链表/红黑树的数据结构来实现，并发控制使用 `synchronized` 和 CAS 来操作。
	- `synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，效率又提升 N 倍。

`Hashtable`： 

- 数组 + 链表组成的，数组是 `Hashtable` 的主体，链表则是主要为了解决哈希冲突而存在的。
- `Hashtable` 是线程安全的，因为 `Hashtable` 内部的方法基本都经过 `synchronized` 修饰。
- 但是它是全表锁，也就是把所有数据都锁了起来
- 不允许有 null 键和 null 值

`TreeMap`： 

- 红黑树（自平衡的排序二叉树）
- 相比于 `HashMap` 来说 `TreeMap` 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力

`HashSet` ：

- 底层就是基于 `HashMap` 实现的
- `HashSet` 会先计算对象的 `hashcode` 值来判断对象加入的位置，同时也会与其他加入的对象的 `hashcode` 值作比较，
- 如果没有相符的 `hashcode`，`HashSet` 会假设对象没有重复出现。
- 但是如果发现有相同 `hashcode` 值的对象，这时会调用 `equals()` 方法来检查 `hashcode` 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让加入操作成功。

### HashMap 和 Hashtable 的区别

**线程是否安全：** `HashMap` 是非线程安全的，`Hashtable` 是线程安全的，因为 `Hashtable` 内部的方法基本都经过`synchronized` 修饰。（如果要保证线程安全就使用 `ConcurrentHashMap` ）；

**效率：** 因为线程安全的问题，`HashMap` 要比 `Hashtable` 效率高一点。另外，`Hashtable` 基本被淘汰，不要在代码中使用它；

**对 Null key 和 Null value 的支持：**

-  `HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个
- Hashtable 不允许有 null 键和 null 值，否则会抛出 `NullPointerException`。

**初始容量大小和每次扩充容量大小的不同 ：**

1. 创建时如果不指定容量初始值，`Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。`HashMap` 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。
2. 创建时如果给定了容量初始值，那么 `Hashtable` 会直接使用你给定的大小，而 `HashMap` 会将其扩充为 2 的幂次方大小（`HashMap` 中的`tableSizeFor()`方法保证，下面给出了源代码）。也就是说 `HashMap` 总是使用 2 的幂作为哈希表的大小

**底层数据结构：**

- JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）
- `Hashtable` 没有这样的机制。

### HashMap 和 HashSet 区别

如果你看过 `HashSet` 源码的话就应该知道：`HashSet` 底层就是基于 `HashMap` 实现的。（`HashSet` 的源码非常非常少，因为除了 `clone()`、`writeObject()`、`readObject()`是 `HashSet` 自己不得不实现之外，其他方法都是直接调用 `HashMap` 中的方法。

|               `HashMap`                |                          `HashSet`                           |
| :------------------------------------: | :----------------------------------------------------------: |
|           实现了 `Map` 接口            |                       实现 `Set` 接口                        |
|               存储键值对               |                          仅存储对象                          |
|     调用 `put()`向 map 中添加元素      |             调用 `add()`方法向 `Set` 中添加元素              |
| `HashMap` 使用键（Key）计算 `hashcode` | `HashSet` 使用成员对象来计算 `hashcode` 值，对于两个对象来说 `hashcode` 可能相同，所以`equals()`方法用来判断对象的相等性 |

### HashMap 和 TreeMap 区别

`TreeMap` 和`HashMap` 都继承自`AbstractMap` ，但是需要注意的是`TreeMap`它还实现了`NavigableMap`接口和`SortedMap` 接口。

![TreeMap 继承关系图](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/treemap_hierarchy.png)

实现 `NavigableMap` 接口让 `TreeMap` 有了对集合内元素的搜索的能力。

实现`SortedMap`接口让 `TreeMap` 有了对集合中的元素根据键排序的能力。默认是按 key 的升序排序，不过我们也可以指定排序的比较器。示例代码如下：



```java
/**
 * @author shuang.kou
 * @createTime 2020年06月15日 17:02:00
 */
public class Person {
    private Integer age;

    public Person(Integer age) {
        this.age = age;
    }

    public Integer getAge() {
        return age;
    }


    public static void main(String[] args) {
        TreeMap<Person, String> treeMap = new TreeMap<>(new Comparator<Person>() {
            @Override
            public int compare(Person person1, Person person2) {
                int num = person1.getAge() - person2.getAge();
                return Integer.compare(num, 0);
            }
        });
        treeMap.put(new Person(3), "person1");
        treeMap.put(new Person(18), "person2");
        treeMap.put(new Person(35), "person3");
        treeMap.put(new Person(16), "person4");
        treeMap.entrySet().stream().forEach(personStringEntry -> {
            System.out.println(personStringEntry.getValue());
        });
    }
}
```

输出:



```text
person1
person4
person2
person3
```

可以看出，`TreeMap` 中的元素已经是按照 `Person` 的 age 字段的升序来排列了。

上面，我们是通过传入匿名内部类的方式实现的，你可以将代码替换成 Lambda 表达式实现的方式：



```java
TreeMap<Person, String> treeMap = new TreeMap<>((person1, person2) -> {
  int num = person1.getAge() - person2.getAge();
  return Integer.compare(num, 0);
});
```

**综上，相比于`HashMap`来说 `TreeMap` 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力。**

### HashSet 如何检查重复?

以下内容摘自我的 Java 启蒙书《Head first java》第二版：

> 当你把对象加入`HashSet`时，`HashSet` 会先计算对象的`hashcode`值来判断对象加入的位置，同时也会与其他加入的对象的 `hashcode` 值作比较，如果没有相符的 `hashcode`，`HashSet` 会假设对象没有重复出现。但是如果发现有相同 `hashcode` 值的对象，这时会调用`equals()`方法来检查 `hashcode` 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让加入操作成功。

在 JDK1.8 中，`HashSet`的`add()`方法只是简单的调用了`HashMap`的`put()`方法，并且判断了一下返回值以确保是否有重复元素。直接看一下`HashSet`中的源码：



```java
// Returns: true if this set did not already contain the specified element
// 返回值：当 set 中没有包含 add 的元素时返回真
public boolean add(E e) {
        return map.put(e, PRESENT)==null;
}
```

而在`HashMap`的`putVal()`方法中也能看到如下说明：



```java
// Returns : previous value, or null if none
// 返回值：如果插入位置没有元素返回null，否则返回上一个元素
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
...
}
```

也就是说，在 JDK1.8 中，实际上无论`HashSet`中是否已经存在了某元素，`HashSet`都会直接插入，只是会在`add()`方法的返回值处告诉我们插入前是否存在相同元素。

### HashMap 的底层实现

**JDK1.8 之前**

JDK1.8 之前 `HashMap` 底层是 **数组和链表** 结合在一起使用也就是 **链表散列**。HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。

所谓扰动函数指的就是 HashMap 的 `hash` 方法。使用 `hash` 方法也就是扰动函数是为了防止一些实现比较差的 `hashCode()` 方法 换句话说使用扰动函数之后可以减少碰撞。

**JDK 1.8 HashMap 的 hash 方法源码:**

JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，但是原理不变。



```java
    static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
```

对比一下 JDK1.7 的 HashMap 的 hash 方法源码.



```java
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).

    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}
```

相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。

所谓 **“拉链法”** 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。

![jdk1.8 之前的内部结构-HashMap](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/jdk1.7_hashmap.png)

---

**JDK1.8 之后**

相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

![jdk1.8之后的内部结构-HashMap](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/jdk1.8_hashmap.png)

> TreeMap、TreeSet 以及 JDK1.8 之后的 HashMap 底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。

我们来结合源码分析一下 `HashMap` 链表到红黑树的转换。

**1、 `putVal` 方法中执行链表转红黑树的判断逻辑。**

链表的长度大于 8 的时候，就执行 `treeifyBin` （转换红黑树）的逻辑。



```java
// 遍历链表
for (int binCount = 0; ; ++binCount) {
    // 遍历到链表最后一个节点
    if ((e = p.next) == null) {
        p.next = newNode(hash, key, value, null);
        // 如果链表元素个数大于等于TREEIFY_THRESHOLD（8）
        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
            // 红黑树转换（并不会直接转换成红黑树）
            treeifyBin(tab, hash);
        break;
    }
    if (e.hash == hash &&
        ((k = e.key) == key || (key != null && key.equals(k))))
        break;
    p = e;
}
```

**2、`treeifyBin` 方法中判断是否真的转换为红黑树。**



```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    // 判断当前数组的长度是否小于 64
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        // 如果当前数组的长度小于 64，那么会选择先进行数组扩容
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        // 否则才将列表转换为红黑树

        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
```

将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树。

### HashMap 的长度为什么是 2 的幂次方

为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash 值的范围值-2147483648 到 2147483647，前后加起来大概 40 亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40 亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ `(n - 1) & hash`”。（n 代表数组长度）。这也就解释了 HashMap 的长度为什么是 2 的幂次方。

**这个算法应该如何设计呢？**

我们首先可能会想到采用%取余的操作来实现。但是，重点来了：**“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是 2 的 n 次方；）。”** 并且 **采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。**

### HashMap 多线程操作导致死循环问题

主要原因在于并发下的 Rehash 会造成元素之间会形成一个循环链表。不过，jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。

详情请查看：[https://coolshell.cn/articles/9606.htmlopen in new window](https://coolshell.cn/articles/9606.html)

### HashMap 有哪几种常见的遍历方式?

[HashMap 的 7 种遍历方式与性能分析！open in new window](https://mp.weixin.qq.com/s/zQBN3UvJDhRTKP6SzcZFKw)

### ConcurrentHashMap 和 Hashtable 的区别

`ConcurrentHashMap` 和 `Hashtable` 的区别主要体现在实现线程安全的方式上不同。

- **底层数据结构：** JDK1.7 的 `ConcurrentHashMap` 底层采用 **分段的数组+链表** 实现，JDK1.8 采用的数据结构跟 `HashMap1.8` 的结构一样，数组+链表/红黑二叉树。`Hashtable` 和 JDK1.8 之前的 `HashMap` 的底层数据结构类似都是采用 **数组+链表** 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；
- 实现线程安全的方式（重要）：
  - 在 JDK1.7 的时候，`ConcurrentHashMap` 对整个桶数组进行了分割分段(`Segment`，分段锁)，每一把锁只锁容器其中一部分数据（下面有示意图），多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。
  - 到了 JDK1.8 的时候，`ConcurrentHashMap` 已经摒弃了 `Segment` 的概念，而是直接用 `Node` 数组+链表+红黑树的数据结构来实现，并发控制使用 `synchronized` 和 CAS 来操作。（JDK1.6 以后 `synchronized` 锁做了很多优化） 整个看起来就像是优化过且线程安全的 `HashMap`，虽然在 JDK1.8 中还能看到 `Segment` 的数据结构，但是已经简化了属性，只是为了兼容旧版本；
  - **`Hashtable`(同一把锁)** :使用 `synchronized` 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

下面，我们再来看看两者底层数据结构的对比图。

**Hashtable** :

![Hashtable 的内部结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/jdk1.7_hashmap.png)

https://www.cnblogs.com/chengxiao/p/6842045.html>

**JDK1.7 的 ConcurrentHashMap** ：

![Java7 ConcurrentHashMap 存储结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/java7_concurrenthashmap.png)

`ConcurrentHashMap` 是由 `Segment` 数组结构和 `HashEntry` 数组结构组成。

`Segment` 数组中的每个元素包含一个 `HashEntry` 数组，每个 `HashEntry` 数组属于链表结构。

**JDK1.8 的 ConcurrentHashMap** ：

![Java8 ConcurrentHashMap 存储结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/java8_concurrenthashmap.png)

JDK1.8 的 `ConcurrentHashMap` 不再是 **Segment 数组 + HashEntry 数组 + 链表**，而是 **Node 数组 + 链表 / 红黑树**。不过，Node 只能用于链表的情况，红黑树的情况需要使用 **`TreeNode`**。当冲突链表达到一定长度时，链表会转换成红黑树。

`TreeNode`是存储红黑树节点，被`TreeBin`包装。`TreeBin`通过`root`属性维护红黑树的根结点，因为红黑树在旋转的时候，根结点可能会被它原来的子节点替换掉，在这个时间点，如果有其他线程要写这棵红黑树就会发生线程不安全问题，所以在 `ConcurrentHashMap` 中`TreeBin`通过`waiter`属性维护当前使用这棵红黑树的线程，来防止其他线程的进入。



```java
static final class TreeBin<K,V> extends Node<K,V> {
        TreeNode<K,V> root;
        volatile TreeNode<K,V> first;
        volatile Thread waiter;
        volatile int lockState;
        // values for lockState
        static final int WRITER = 1; // set while holding write lock
        static final int WAITER = 2; // set when waiting for write lock
        static final int READER = 4; // increment value for setting read lock
...
}
```

### ConcurrentHashMap 线程安全的具体实现方式/底层具体实现

**JDK1.8 之前**

![Java7 ConcurrentHashMap 存储结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/java7_concurrenthashmap.png)

首先将数据分为一段一段（这个“段”就是 `Segment`）的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。

**`ConcurrentHashMap` 是由 `Segment` 数组结构和 `HashEntry` 数组结构组成**。

`Segment` 继承了 `ReentrantLock`,所以 `Segment` 是一种可重入锁，扮演锁的角色。`HashEntry` 用于存储键值对数据。



```java
static class Segment<K,V> extends ReentrantLock implements Serializable {
}
```

一个 `ConcurrentHashMap` 里包含一个 `Segment` 数组，`Segment` 的个数一旦**初始化就不能改变**。 `Segment` 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。

`Segment` 的结构和 `HashMap` 类似，是一种数组和链表结构，一个 `Segment` 包含一个 `HashEntry` 数组，每个 `HashEntry` 是一个链表结构的元素，每个 `Segment` 守护着一个 `HashEntry` 数组里的元素，当对 `HashEntry` 数组的数据进行修改时，必须首先获得对应的 `Segment` 的锁。也就是说，对同一 `Segment` 的并发写入会被阻塞，不同 `Segment` 的写入是可以并发执行的。

---

 **JDK1.8 之后**

![Java8 ConcurrentHashMap 存储结构](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/collection/java8_concurrenthashmap.png)

Java 8 几乎完全重写了 `ConcurrentHashMap`，代码量从原来 Java 7 中的 1000 多行，变成了现在的 6000 多行。

`ConcurrentHashMap` 取消了 `Segment` 分段锁，采用 `Node + CAS + synchronized` 来保证并发安全。数据结构跟 `HashMap` 1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。

Java 8 中，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。

### JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现有什么不同？

- **线程安全实现方式** ：JDK 1.7 采用 `Segment` 分段锁来保证安全， `Segment` 是继承自 `ReentrantLock`。JDK1.8 放弃了 `Segment` 分段锁的设计，采用 `Node + CAS + synchronized` 保证线程安全，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点。
- **Hash 碰撞解决方法** : JDK 1.7 采用拉链法，JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。
- **并发度** ：JDK 1.7 最大并发度是 Segment 的个数，默认是 16。JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。

## Collections 工具类（不重要）

**`Collections` 工具类常用方法**:

- 排序
- 查找,替换操作
- 同步控制(不推荐，需要线程安全的集合类型时请考虑使用 JUC 包下的并发集合)

### 排序操作



```java
void reverse(List list)//反转
void shuffle(List list)//随机排序
void sort(List list)//按自然排序的升序排序
void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑
void swap(List list, int i , int j)//交换两个索引位置的元素
void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面
```

### [#](#查找-替换操作) 查找,替换操作



```java
int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的
int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)
int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)
void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素
int frequency(Collection c, Object o)//统计元素出现次数
int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target)
boolean replaceAll(List list, Object oldVal, Object newVal)//用新元素替换旧元素
```

### [#](#同步控制) 同步控制

`Collections` 提供了多个`synchronizedXxx()`方法·，该方法可以将指定集合包装成线程同步的集合，从而解决多线程并发访问集合时的线程安全问题。

我们知道 `HashSet`，`TreeSet`，`ArrayList`,`LinkedList`,`HashMap`,`TreeMap` 都是线程不安全的。`Collections` 提供了多个静态方法可以把他们包装成线程同步的集合。

**最好不要用下面这些方法，效率非常低，需要线程安全的集合类型时请考虑使用 JUC 包下的并发集合。**

方法如下：

```java
synchronizedCollection(Collection<T>  c) //返回指定 collection 支持的同步（线程安全的）collection。
synchronizedList(List<T> list)//返回指定列表支持的同步（线程安全的）List。
synchronizedMap(Map<K,V> m) //返回由指定映射支持的同步（线程安全的）Map。
synchronizedSet(Set<T> s) //返回指定 set 支持的同步（线程安全的）set。
```



# Spring

## Spring 的优点

Spring 的优点：

* 解耦，简化开发。通过 Spring 提供的 IoC 容器，可以由 Spring 管理控制对象，避免程序过度耦合
* 不用再为了单例模式和读取配置等底层的需求编写代码，可以专注于上层的应用
* 支持 AOP，实现传统 OOP 所不能实现的功能
* 支持声明式事务。通过声明的方式灵活管理事务，提高开发效率和质量
* Spring 生态强大，方便集成各种优秀框架
* 便于学习 Java 源码

## Spring Boot 的自动装配

在 Spring Boot 中，我们直接引入一个 starter 和少量注解即可完成配置。

SpringBoot 的核心注解 `@SpringBootApplication` 是 `@SpringBootConfiguration`、`@EnableAutoConfiguration`、`@ComponentScan` 注解的组合：

- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
- `@ComponentScan`： 扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。
- `@SpringBootConfiguration`：其实就是 `@Configuration` ，允许在上下文中注册额外的 bean 或导入其他配置类

`@EnableAutoConfiguration` 只是一个简单地注解，自动装配核心功能的实现实际是通过 `AutoConfigurationImportSelector` 类：

- `AutoConfigurationImportSelector` 类可以加载自动装配类
- `AutoConfigurationImportSelector` 类实现了 `ImportSelector`接口，也就实现了这个接口中的 `selectImports` 方法，该方法主要用于**获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中**。
- 它会获取需要自动装配的所有配置类，读取所有 starters 的 `META-INF/spring.factories`
- 不是所有的 spring.factories 中的配置都会被加载，因为有一个 `@ConditionalOnXXX` 的注解来确立生效条件

总结：Spring Boot 通过 `@EnableAutoConfiguration` 开启自动装配，通过 SpringFactoriesLoader 最终加载 `META-INF/spring.factories` 中的自动配置类实现自动装配，自动配置类其实就是通过 `@Conditional` 按需加载的配置类，想要其生效必须引入 `spring-boot-starter-xxx` 包实现起步依赖。

# MySQL 索引

## 为什么要用索引（对比“页结构”）

索引是一种用于快速查询和检索数据的排好序的数据结构。

如果没有索引，读取数据库中的数据的时候，需要不断地将磁盘中的数据，读取到内存中进行查找操作，这会产生大量 IO 操作，效率很低。

> 操作系统读取数据，是按照“页（page）”为单位的，也就是 1 页、2 页这样读取。
>
> - 在“页结构”中，数据分为多**页**。
>
> - 每一页有一个**页目录**，该**页目录**存储**用户数据区域**中，某个区间的头数据
> - **用户数据区域**就是存储的数据
> - 在查找的时候，会进入每一页，然后查找每一页的页目录，然后再找到数据。如果找不到，就进入下一页继续查找。

索引就相当于将“页”（Page）中，最大和最小的页目录，直接抽取出来。这样就不用每一页都查找，而是直接找到该页数据，直接访问数据，效率很高。

“索引”可以被叫做“索引页”。普通的“页”，就叫做“数据页”。

## 索引的数据结构

常见的索引结构有: B 树， B+ 树和 Hash。

Hash，数组+链表，问题是不支持范围查找：

```
[0]->[][][][][]
[1]->[][][][][]
[2]->[][][][][]
[3]->[][][][][]
```

B 树：

```
		[2]
	/		\
[1]		[3]
```

B+ 树：

```
				[1,9]
				/		\
[1,2,3,4(*1)]<-->[(*2)9,10,11,12]

*1：留出一小块空间，存放右边叶子结点的磁盘文件地址
*2：留出一小块空间，存放左边叶子结点的磁盘文件地址
```

为什么不让树的高度为 1？

- 因为查找的时候，需要一层一层地将数据加载到内存中查找。
- 如果一次性全部数据加载到内存中的话就会出现问题。

假设是 `select x from table where a > 5`，会怎么走索引？

- 会先执行  `select x from table where a = 5`，然后把大于的值全部返回就行

## 索引的优缺点

**优点** ：

- 使用索引可以大大加快数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。
- 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性，方便添加行锁。

**缺点** ：

- 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
- 索引需要使用物理文件存储，也会耗费一定空间。

但是，**使用索引一定能提高查询性能吗?**

大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。

## 聚集索引和非聚集索引

这两个是数据组织的一种方式，不是真正意义上的索引。

聚集索引：

- 索引结构和数据一起存放的索引。
- 主键索引属于聚集索引。所以建议 InnoDB 建立整型的自增主键。

非聚集索引：

- 索引文件和数据文件是分开存放的
- 非聚集索引需要“回表”，也就是查找一次索引，再回到表中读取数据，所以没那么快

## 索引类型

### 主键索引(Primary Key)

数据表的主键列使用的就是主键索引。

**有唯一标识，主键不可重复，只能有一个列作为主键**。

一张数据表有只能有一个主键，并且主键不能为 null，不能重复。

### 二级索引(辅助索引 Secondary Key)

1. **唯一索引(Unique Index)** ：
	* 唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
	* 这里的 "唯一" 是单独这一列唯一，我们希望身份证号是"唯一"的，银行卡号也必须"唯一"的。但不是说，有了身份证号，就不能有银行卡。
2. **普通索引(Index)** ：
	* **普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**
	* 默认的索引，使用 index 或 key 来设置
3. **前缀索引(Prefix)** ：
	* 前缀索引**只适用于字符串类型的数据**。
	* 前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
4. **全文索引(Full Text)** ：
	* 全文索引主要是**为了检索大文本数据中的关键字的信息**，是目前搜索引擎数据库使用的一种技术。
	* MySQL 5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。

## 索引原则

适合：

- 索引一般加在频繁用来查询的字段上
- 在字符串类型的字段上使用前缀索引代替普通索引
- 关联字段需要建立索引，比如：外键字段
- 排序字段 order by
- 分组字段 group by（分组也是建立在排序基础上）
- 统计字段 count()，max() 这些

不适合：

- 索引不是越多越好
- 不要对经常变动的数据加索引
- 小数据量的表不需要加索引
- 注意避免冗余索引
- where 条件中用不到的字段不要建立索引
- 重复度高的字段，不适合建立索引。比如：男女，真假

## 联合索引 与 最左前缀匹配原则

索引是一种排好序的数据结构。对于单值索引而已，值只有一个，所以容易排序。

>**联合索引**，也叫 **组合索引** 或 **复合索引**。是最常见的。

对于联合索引而言，遵从**最左前缀匹配原则**，也就是从左到右依次匹配索引的值。

假设索引是 `name, age, gender`，只有以 `name` 开头的语句才会走索引。也就是不能跳过最左的值。

**最左前缀匹配原则**的原理：

```
				[a,1]								[d,1]
	/				|			\				/			|			\
[a, 1]	[b,3]	[c,2]		[d,1]	[e,2]	[f,1]
```

如果不是按照从左到右（也就是上面的字母->数字）的顺序的话，假设先以数字 2 开头，那么就要把所有数据都遍历一遍，这样就不是“排好序”的数据结构了。

也就说，必须要**满足有序性**，所以一定要从左到右依次匹配，才能满足有序性。

## 使用短索引

可以截取有区分度的一部分作为索引。比如 "baidu.com/fjiefibfiebufbue"，只需要截取到 "baidu.com" 作为索引就可以了。

## 索引失效的条件

1. **索引不能为 null，有一定几率会失效**

因为无法比较值的大小。这也是为什么主键不能为 null 的原因。

使用 `is null` 的时候，优化器根据 null/not null 的数量占比来决定是否走索引，使用有一定几率索引失效

解决方案是给一个特殊的值，比如 age 为 -1 就是特殊的值，来替换 null。

---

2. **每次查询，都只用一个索引**

如果 where 子句已经使用了索引，那么 order by 的时候是不会使用索引的。

*尽量使用联合索引*：比如 a,b,c 都建立索引，那么只会 a 的索引生效。所以要将 abc 设置为联合索引。

---

3. **使用 or 的时候，如果 or 的两边是单列索引会走，如果是联合索引会失效。**

假设是 `select * from a where id = 1 or uid = 2;` ，那么如果 id 加了索引，而 uid 没有加索引，那么就会失效。

如果要让索引生效，就必须 id 和 uid 都加上单列索引（注意，不是联合索引）。

---

4. **参与了列计算的列，索引会失效**

列计算：加减乘除，日期的计算，日期的格式化等等

5. **不符合最左原则，索引会失效**

6. **like 查询以 % 开头，索引会失效**

7. **MySQL 如果认为全表扫描速度更快，就不会走索引**
8. 使用了 `select *`

>使用 `select *` 的话，当走完索引之后，不知道要返回什么列。
>
>如果有使用主键（Primary Key），那么索引走到尾巴的时候，其实就会存储主键。
>
>此时就通过主键，去**回表**，查找主键索引里面存储的列数据。
>
>补充知识点：
>
>1. 如果没有指定主键，数据库会创建隐藏的主键
>2. 存储主键，而不是完整的数据，是因为索引扫描的时候，如果存储完整的数据，数据量就大，扫描就会很慢
>
>比如说，`select * from table where a > 5`，此时，即便通过索引找到了 a > 5 的值，然而由于不知道列数据，所以需要一直回表去查列数据。
>
>如果回表次数比较少，是有可能走索引的。但是如果回表次数比较多，此时效率还不如全表扫描块，所以就不会走索引了。

> 假设联合索引是 a,b，那么 `select a, b from table where b = 1 and a = 2` 和  `select a, b from table where a = 1 and b = 2` 一样，也是会走索引的。
>
> “最左前缀原则” 和 where 后面的 and 条件的顺序无关。

> 假设联合索引是 a,b,c，那么 `select a, b from table where a > 5` 是会走索引的，因为 `select a, b` 中的 `a, b` 字段有存储在联合索引中。 

# MySQL 事务

## MySQL 事务的 4 大特性

ACID：

- Atomicity 原子性：多个动作，要么一起成功，要么一起失败
- Consistency 一致性：当事务完成时，必须使所有数据都具有一致的状态，保证数据的完整性
- Isolation 隔离性：多个用户同时操作，要排除其他业务对当前业务的影响
- Durability 持久性：只要事务提交了，就会持久化到数据库，造成永久的影响

## MySQL 事务隔离级别

隔离所导致的问题：

- 脏读（Dirty read）：一个事务读取了另一个事务还未提交的数据
- 不可重复读（Unrepeatableread）：读取表中某行数据时，多次读取的结果不同（可能因为刚好数据更新了，所以不一定是错误）
- 幻读（虚读 Phantom read）：读取到了别的事务插入（或删除）的数据（第一次没读到，第二次发现读到了；或第一次读到，第二次又读不到）
- 丢失修改（Lost to modify）：
	- 在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。
	- 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。


事务的隔离级别：

- Read Uncommitted：
	- 读未提交
	- 即使一个更新语句没有提交，但是别的事务可以读到这个改变。
	- 这是很不安全的。因为别人可能会 rollback（回滚）
	- 允许任务读取数据库中未提交的数据更改，也称为脏读。
	- 问题：脏读、不可重复读、幻读（虚读）
- Read Committed：
	- 读已提交
	- 可防止脏读。语句提交以后即执行了 COMMIT 以后别的事务就能读到这个改变. 只能读取到已经提交的数据。
	- 问题：不可重复读、幻读（虚读）
- Repeatable Read：
	- 可重复读
	- 同一个事务里面先后执行同一个查询语句的时候，得到的结果是一样的。
	- 在同一个事务内的查询都是事务开始时刻一致的，InnoDB默认级别。
	- 问题：幻读（虚读）
- Serializable：
	- 串行化
	- 这个事务执行的时候不允许别的事务并发执行。
	- 完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞

## MySQL表锁和行锁

- **表级锁：** 
	- MySQL 中锁定 **粒度最大** 的一种锁，对当前操作的整张表加锁
	- 实现简单，资源消耗也比较少，加锁快，基本不会出现死锁。
	- 其锁定粒度最大，触发锁冲突的概率最高，并发度最低
	- MyISAM 和 InnoDB 引擎都支持表级锁。
- **行级锁：** 
	- MySQL 中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。
	- 行级锁能大大减少数据库操作的冲突。
	- 其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。

## InnoDB 存储引擎的锁

Record Lock 记录锁

- 如果没有索引，就是表锁。
- 如果有索引，就是行锁。

Gap lock：间隙锁

- 当查询一个范围的时候，锁定一个范围
- 但是不包括记录本身

Next-key lock：临键锁 = 间隙锁 + 记录锁

- 锁定一个范围，包含记录本身
- 目的：避免幻读

MDL 锁：

- 上锁，防止有人修改表结构

## 解决死锁

- 尽量让数据表中的数据检索都通过索引来完成，避免无效索引导致行锁升级为表锁。
- 合理设计索引，尽量缩小锁的范围。
- 尽量减少查询条件的范围，尽量避免间隙锁或缩小间隙锁的范围。
- 尽量控制事务的大小，减少一次事务锁定的资源数量，缩短锁定资源的时间。
- 如果一条SQL语句涉及事务加锁操作，则尽量将其放在整个事务的最后执行。尽可能使用低级别的事务隔离机制。

## 乐观锁和悲观锁

悲观锁：手动上锁

乐观锁：加一个 version 字段，每次 update 的时候都带上 version 的判断条件。

# MySQL

## 数据库的列类型

char & varchar

- char 0-255 固定大小
- varchar 0-65535 可变字符串

时间日期：

- date：YYYY-MM-DD
- time：HH:mm:ss
- datetime：YYYY-MM-DD HH:mm:ss
- timestamp
- year

# SQL

## SQL 优化

> 使用 `explain` 分析 SQL 语句，主要查看 `rows`

总结到SQL优化中，就三点:

- 正确建立索引，最大化利用索引；
- 尽可能避免全表扫描；
- 减少无效数据的查询

具体而言：

- 避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描：
	- `SELECT * FROM t WHERE username LIKE '%陈%';` 中的 `'%陈%'` 替换为 `'陈%'`
	- 可以使用 FullText 全文索引，用 match against 检索
	- 如果数据量大，使用 Elasticsearch
	- 如果数据量小，直接 `% %` 也没什么关系
- 避免出现不确定结果的函数

- SELECT 语句指明字段名称，尽量不要使用 `*`
- 只查询一条数据的时候，使用 limit 1
- 避免出现不确定结果的函数（避免出现 now()、rand()、sysdate()、current_user() 等）
- 使用表的别名，减少解析时间
- 禁止使用不含字段列表的 INSERT 语句：
	- 不要使用：`insert into t values ('a','b','c');`
	- 而要使用：`insert into t(c1,c2,c3) values ('a','b','c');`
- 对应同一列进行 or 判断时，使用 in 代替 or：
	- in 的值不要超过 500 个，in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。
- 避免使用 JOIN 关联太多的表
- 避免使用子查询，可以把子查询优化为 join 操作

# MyBatis

## MyBatis ${} 与#{} 拼接字符串区别

`#{}` 是编译好 SQL 语句，再取值的占位符号，是安全的：

```sql
# 这条 SQL
select * from emp where name = #{employeeName};
# 会被转换为：
select * from emp where name = 'Smith'; 
```

`${}` 是取值以后，再去编译SQL语句的拼接符号，是非安全的，存在 SQL 注入：

```sql
# 这条 SQL
select * from emp where name = ${employeeName};
# 会被转换为：
select * from emp where name = Smith
```

## like 拼接参数

1. `like '%${XX}%'`
2. `like "%"#{XX}"%"`
	- 因为 `#{...}` 解析成 sql 语句时候，会在变量外侧自动加单引号 `''`
	- 所以这里 `%` 需要使用双引号 `""`，不能使用单引号 `''`，不然会查不到任何结果
3. 使用 `CONCAT()` 函数连接参数形式
	- `like concat(concat("%",#{eventDto.eventContent}),"%")`
	- 建议使用这一种，函数连接字符串

# Redis

## Redis 的基本数据结构

Redis 的基本数据结构：

- String 字符串类型
- List 列表类型
- Set 集合类型
- Hash 哈希类型
- Zset 有序集合类型
- Geospatial 地理位置信息
- Hyperloglog 基数统计
- Bitmap 位图场景

## Redis 过期数据的删除策略

定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性/懒汉式删除 。

### 惰性删除 / 被动删除策略

当读/写一个 key 时，如果发现它是过期的，就把它删除掉。

缺点是，有些过期的数据，只要没被读/写，就一直不会被删除。

### 定期删除 / 主动删除策略

每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

## Redis 淘汰策略

当内存的使用率达到 Max memory 的上限的时候，Redis 释放内存的一种行为。

### Redis 数据淘汰策略

> **volatile** 已经设置过期时间 key 集合。
>
> **allkeys** 所有 key 集合。

volatile-lru：

- least recently used
- 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰

volatile-ttl：

- 从已设置过期时间的数据集中挑选将要过期的数据淘汰

volatile-random：

- 从已设置过期时间的数据集中任意选择数据淘汰

volatile-lfu：

- 4.0 版本后增加
- least frequently used
- 从已设置过期时间的数据集中挑选最不经常使用的数据淘汰

allkeys-lru：

- least recently used
- 当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）

allkeys-random：

- 从数据集中任意选择数据淘汰

allkeys-lfu：

- 4.0 版本后增加
- least frequently used
- 当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

no-eviction：

- 禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错

## Redis 内存淘汰算法

Random 随机

- 随机淘汰某个 key

TTL 算法

- 在设置了过期时间的 key 里面，找到更快要过期的 key，进行有限移除

LRU 算法

- 移除最近很少使用的 key

- LRU 是常见的内存淘汰算法，Redis 里面维护一个大小为 16 的候选池，候选池里面的数据会根据时间进行排序
- 每次随机抽取 5 个 key，放到候选池里面。当候选池满了后，访问时间间隔最大的 key，就会从候选池里面淘汰掉。
- 通过这个设计，可以把真实的最少访问的 key，从内存中淘汰。
- 缺点：假如一个 key，长时间没被访问，但是最近一次偶然被访问到，就会被识别为热门 key，不会被淘汰

LFU 算法

- 为了解决 LRU 的问题，Redis 4 以后，增加了 LFU 算法。
- LFU 增加了访问频率的维度，来统计数据的热点情况。
- LFU 主要使用了 2 个双向链表。形成二维的双向链表。
- 一个用来保存访问的频率，另一个保存访问频率相同的 key。
- 当添加元素的时候，访问频率默认为 1。找到相同频率节点对应的双向链表的头部。
- 当元素被访问的时候，会增加 key 对应的访问频率，并且把当前访问的节点，移动到 +1 频率的节点。
- 如果单纯按照访问频率进行淘汰的话，假如一个 key 早期频繁被访问，后期没被访问，也很难被淘汰掉。
- 所以 LFU 通过使用频率和上次访问时间，来标记数据的热度。
- 缺点：LFU 需要维护访问频次，复杂度增高

# 多线程 / 并发

## 线程的 6 种状态

使用 getState() 可以获取线程的 **6** 种状态

- NEW：新线程
- RUNNABLE：可运行状态
- BLOCKED：
	- 阻塞状态
	- 等待/拿到同步锁
- WAITING：
	- 等待状态
	- 等待其他线程的通知/收到通知，继续执行
- TIMED_WAITING：
	- 定时等待
	- 超时等待
- TERMINATED：终止状态

## 线程和进程?

- 进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。
- 线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。

## 调用线程的 4 种方式

1. 继承 Thread 类，重写 run 方法
2. 实现 Runnable 接口创建任务，并交由 Thread 执行执行该任务
3. 实现 Callable 接口，并配合 FutureTask 实现线程的阻塞调用，并将结果返回。
4. 利用线程池调用线程

## 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

调用 `start()` 方法方可启动线程并使线程进入就绪状态，而 `run()` 方法只是 thread 的一个普通方法调用，还是在主线程里执行。

## 死锁

产生死锁的必要条件：

1. 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用
2. 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放
4. 环路等待条件：在发生死锁时，必然存在一个进程–资源的环形链

预防死锁：

1. 资源一次性分配：一次性分配所有资源，这样就不会再有请求了：（破坏请求条件）
2. 只要有一个资源得不到分配，也不给这个进程分配其他的资源：（破坏请保持条件）
3. 可剥夺资源：即当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源（破坏不可剥夺条件）
4. 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

## synchronized 关键字的底层实现

> 可以联系 JVM 底层来回答。

- 进入时，执行 monitorenter，将计数器 +1，释放锁 monitorexit 时，计数器 −1
- 当一个线程判断到计数器为 0 时，则当前锁空闲，可以占用；反之，当前线程进入等待状态

Synchronized 是在加锁，加对象锁。

对象锁是一种重量锁（Monitor），Synchronized 的锁机制会根据线程竞争情况在运行时会有偏向锁（单一线程）、轻量锁（多个线程访问 Synchronized 区域）、对象锁（重量锁，多个线程存在竞争的情况）、自旋锁等，该关键字是一个几种锁的封装。

## ThreadLocal（线程局部变量）关键字

当使用 ThreadLocal 维护变量时，其为每个使用该变量的线程提供独立的变量副本，因此每一个线程都可以独立改变自己的副本，而不会影响其他线程对应的副本。

ThreadLocal 内部实现机制：

- 每个线程内部都会维护一个类似 HashMap 的对象，称为 ThreadLocalMap，里边会包含若干的 Entry（K-V 键值对），相应的线程被称为这些 Entry 的属主线程。
- Entry 的 Key 是一个 ThreadLocal 实例，Value 是一个线程特有对象。Entry 的作用是：为其属主线程建立起一个 ThreadLocal 实例与一个线程特有对象之间的对应关系。
- Entry 对 Key 的引用是弱引用；Entry 对 Value 的引用是强引用。

## 内存屏障

编译器和 CPU 会在保证程序输出结果一致的情况下，对代码进行重排序，从指令优化角度提升性能。

而指令重排序可能会带来一个不好的结果，导致 CPU 的高速缓存和内存中数据的不一致。

内存屏障（`Memory Barrier`）就是通过阻止屏障两边的指令重排序从而避免编译器和硬件的不正确优化情况。

## CAS

 CAS：<u>比较并替换（Compare And Swap），是实现并发算法时常用到的一种技术</u>。

CAS 操作包含三个操作数：

1. 内存位置
2. 预期原值
3. 新值

执行 CAS 操作的时候，**将内存位置的值与预期原值比较，如果相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作**。

CAS 是一条 CPU 的原子指令（cmpxchg 指令），不会造成所谓的数据不一致问题，`Unsafe` 提供的 CAS 方法（如 `compareAndSwapXXX`）底层实现即为 CPU 指令 `cmpxchg` 。

在 `Unsafe` 类中，提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的 CAS 操作。以`compareAndSwapInt`方法为例：

```java
public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x);
```

参数中`o`为需要更新的对象，`offset`是对象`o`中整形字段的偏移量，如果这个字段的值与`expected`相同，则将字段的值设为`x`这个新值，并且此更新是不可被中断的，也就是一个原子操作。下面是一个使用`compareAndSwapInt`的例子：

```java
private volatile int a;
public static void main(String[] args){
    CasTest casTest=new CasTest();
    new Thread(()->{
        for (int i = 1; i < 5; i++) {
            casTest.increment(i);
            System.out.print(casTest.a+" ");
        }
    }).start();
    new Thread(()->{
        for (int i = 5 ; i <10 ; i++) {
            casTest.increment(i);
            System.out.print(casTest.a+" ");
        }
    }).start();
}

private void increment(int x){
    while (true){
        try {
            long fieldOffset = unsafe.objectFieldOffset(CasTest.class.getDeclaredField("a"));
            if (unsafe.compareAndSwapInt(this,fieldOffset,x-1,x))
                break;
        } catch (NoSuchFieldException e) {
            e.printStackTrace();
        }
    }
}
```

运行代码会依次输出：

```text
1 2 3 4 5 6 7 8 9
```

在上面的例子中，使用两个线程去修改 `int` 型属性 `a` 的值，流程如下所示：

![img](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/basis/unsafe/image-20220717144939826.png)

需要注意的是，<u>在调用 `compareAndSwapInt` 方法后，会直接返回 `true` 或 `false` 的修改结果，因此需要我们在代码中手动添加**自旋**的逻辑</u>。<u>在 `AtomicInteger` 类的设计中，也是采用了将 `compareAndSwapInt` 的结果作为循环条件，直至修改成功才退出死循环的方式来实现的原子性的自增操作</u>。

# 反射

## 反射作用

Java 为静态语言，通过反射使其具有动态性：

- 类在创建后，还可以动态改变一些类的数据
- 获取运行时，类的内部信息，可以直接操作类的内部属性和方法
- 最常用是反射获取注解
- 很多框架里面应用的动态代理，也是反射的功能
- Spring 框架中就是通过反射来创建对象，从而降低系统耦合度的

## 反射基础

优点：动态创建对象，很灵活
缺点：影响性能。反射是解释操作，告诉 JVM 要做什么

Class.forName:

- Class.forName("类名") 获取 Class，Class 包含类信息。每个 Class 在 JVM 中只有一个 Class 实例。Class 对象对应的是加载到 JVM 中的 class 文件
- newInstance() 方法，调用无参构造器，创建实例
- get interface, get class loader, get constructors, get methods, get declared fields
- 初始化的时候，JVM 使用 client 指令初始化（静态变量，静态代码块，代码块，构造方法），如果父类没有初始化，就先初始化父类。

## AOP 的底层实现原理

- JDK 的 java.lang.reflect 的 `InvocationHandler` 接口
- Cglib 的 Enhancer 继承原始类

## 创建代理的三要素

1. 原始对象
2. 额外功能
3. 让代理对象和原始对象实现相同的接口

**让代理对象和原始对象实现相同的接口**的原因：

1. 保证 *代理类* 和 *原始类* 方法一致，迷惑调用者
2. 代理类可以在执行原始方法的前后（包括抛出异常），添加额外的功能

# WebService

一个部署在Web服务器上，**向外界暴露出一个能够通过 Web 进行调用的 API**。

也就是说：当我们想要获取天气预报的信息，我们可以调用别人写好的service服务，我们调用就能够得到结果了

**WebService 实际上就是 http + XML**

# Java

## 多态、继承和封装 —— 面向对象的三大特征

多态：

- 定义：一个对象具有多种的状态，具体表现为 *父类的引用* 指向 *子类的实例*
- *对象类型* 和 *引用类型* 之间具有<u>继承（类）/实现（接口）</u>的关系
- *引用类型变量* 调用的到底是哪个类中的方法，必须在程序运行期间才能确定
- 多态不能调用“只在子类存在但在父类不存在”的方法
- 如果子类重写了父类的方法，执行的是子类覆盖的方法；如果子类没有覆盖父类的方法，执行的是父类的方法

继承：

- 继承是使用已存在的类的定义作为基础建立新类的技术。
- 新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。
- 特点：
  - 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，**只是拥有**。
  - 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。
  - 子类可以用自己的方式实现父类的方法。


封装：

- 定义：把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。
- 就好像我们看不到挂在墙上的空调的内部的零件信息（也就是属性），但是可以通过遥控器（方法）来控制空调。
- 如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。

## 抽象类和接口

> 接口只有方法和静态常量。
>
> Java 8 后，接口可以用 default 关键字或 static，实现方法（有方法体）。
>
> Java 9 后，接口可以用 private 关键字实现方法（有方法体）

共同：

- 可以定义抽象方法
- 不能创建本类的实例对象，只能由子类去实例化子类对象
- 都可以有默认实现的方法（Java 8 以后，接口可以用 `default` 关键字定义默认方法）

不同：

- 抽象程度
	- 接口比抽象类更抽象，因为它只有方法。子类实现接口后，只能重写方法
	- 而子类在继承抽象类后，还会把抽象类的成员属性也继承过来
- 子类要扩展时
	- 接口是实现，implements 关键字
		- 接口和接口之间支持多实现，一个类可以实现多个接口
	- 抽象类是继承，extends 关键字
		- 类和类之间只能单继承，一个类只能继承一个类
- 能力
	- 接口：主要用于对类的行为进行约束，你实现了某个接口就具有了对应的行为。
	- 抽象类：主要用于代码复用，强调的是所属关系。
- 构造方法
	- 抽象类中有构造器，用于限定子类的构造行为
		- 抽象类不能被实例化，但它还是有构造器
		- 因为抽象类可以将构造器定义好几个参数，子类必须传入那几个参数
	- 接口没有构造器
- 成员属性（成员变量）
	- 接口不能定义成员属性，只能定义 `public static final` 的静态常量，不能定义静态变量
	- 抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值
- 使用场景
	- 当需要让子类继承成员变量，或者需要控制子类的实例化时，就用抽象类
	- 否则就用接口

## equals()、hashCode() 与 ==

> `hashCode()` 的默认行为是对堆上的对象产生独特值。如果没有重写 `hashCode()`，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。
>
> == 和 hashCode() 没有直接关系

**为什么重写 equals() 时必须重写 hashCode() 方法？**

`hashCode()` 和 `equals()` 都是用来判断对象是否相等的

-  `hashCode()` 是用来快速判断的（比如，在 Map 中定位索引位置），但可能出现误差。

- 当 hash 冲突时，我们就通过 `equals()` 方法，来判断冲突对象是否绝对相等。

- 也就是说，`hashCode()` 用来保证性能，`equals()` 用来保证可靠。

如果只重写了 `hashCode()`

- 当 hash 冲突时，即使两个对象相等，也不会被判定为重复，进而导致存储了一大堆重复的对象。

如果只重写了  `equals()` 

- 那么两个相等的对象，内存地址可能就会不相等，这样还是会造成重复元素的问题。

---

**`==` 与 `equals()` 的区别**

`==` 比较内存地址，`equals()` 比较值。

对于基本类型来说，`==` 比较的是值是否相等；

对于引用类型来说，`==` 比较的是两个引用是否指向同一个对象地址（两者在内存中存放的地址（堆内存地址）是否指向同一个地方）；

对于引用类型（包括包装类型）来说，`equals()` 如果没有被重写，对比它们的地址是否相等；如果 `equals()` 方法被重写（例如 String），则比较的是属性值。

---

扩展：String#equals() 和 Object#equals() 有何区别？

`String` 中的 `equals` 方法是被重写过的，比较的是 String 字符串的值是否相等。 `Object` 的 `equals` 方法是比较的对象的内存地址。

## String、StringBuilder 和 StringBuffer

String：

- 只读字符串
- String 类是 final 类
	- 不可以被继承
	- String 引用的字符串内容是不能被改变的
- 每次对String的操作都会生成新的String对象

StringBuffer / StringBuilder类：

- 可变类
- 表示的字符串对象可以直接进行修改。
- StringBuffer 线程安全

## 基本类型和包装类型

- 默认值：包装类型不赋值就是 `null` ，而基本类型有默认值
- 泛型：包装类型可用于泛型，基本类型不可以
- 基本数据类型占用的空间非常小
- 存放位置：
  - <u>基本类型的局部变量</u>存放在 JVM Stack（Java 虚拟机栈）中的局部变量表中
  - <u>基本类型中，未被 `static` 修饰的成员变量</u>存放在 JVM Heap（Java 虚拟机的堆）中
  - <u>包装类型</u>属于对象类型，几乎所有对象实例都存在于 Heap（堆）中
  - 上面提到的 *几乎所有对象实例* ，是因为 HotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存

## 成员变量与局部变量

语法形式 ：

- <u>成员变量</u>属于类，<u>局部变量</u>是在代码块或方法中定义的变量或是方法的参数
- <u>成员变量</u>可以被 `public`, `private`, `static` 等修饰符所修饰，<u>局部变量</u>不能被访问控制修饰符及 `static` 所修饰
- 相同：成员变量和局部变量都能被 `final` 所修饰。

存储方式 ：

- 如果<u>成员变量</u>是使用 `static` 修饰的，那么这个成员变量是属于类的
- 如果<u>成员变量</u>没有使用 `static` 修饰，这个成员变量是属于实例的，存在于 Heap（栈）中
- <u>局部变量</u>存在于 Stack（栈内存）。

生存时间 ：

- <u>成员变量</u>是对象的一部分，它随着对象的创建而存在
- <u>局部变量</u>随着方法的调用而自动生成，随着方法的调用结束而消亡。

默认值 ：

- 正常情况下，成员变量如果没有被赋初始值，则会自动以类型的默认值而赋值（一种情况例外：被 `final` 修饰的成员变量也必须显式地赋值）
- <u>局部变量</u>不会自动赋值

## Exception 和 Error

![Java 异常类层次结构图](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/basis/types-of-exceptions-in-java.png)

在 Java 中，所有的异常都有一个共同的祖先 `java.lang.Throwable` 类。`Throwable` 类有两个重要的子类：

- **`Exception`**： 程序本身可以处理的异常，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。

- **`Error`** ：`Error` 属于程序无法处理的错误 ，不建议通过`catch`捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。

## Checked Exception 和 Unchecked Exception

Checked Exception：

- 受检查异常 ，Java 代码在编译过程中，如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译。
- 除了`RuntimeException`及其子类以外，其他的`Exception`类及其子类都属于受检查异常
- 常见的受检查异常有： IO 相关的异常、`ClassNotFoundException` 、`SQLException`

Unchecked Exception 即 不受检查异常 ，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。

`RuntimeException` 及其子类都统称为非受检查异常，常见的有：

- `NullPointerException`（空指针错误）
- `IllegalArgumentException`（参数错误比如方法入参类型错误）
- `NumberFormatException`（字符串转换为数字格式错误，`IllegalArgumentException` 的子类）
- `ArrayIndexOutOfBoundsException`（数组越界错误）
- `ClassCastException`（类型转换错误）
- `ArithmeticException`（算术错误）
- `SecurityException` （安全错误比如权限不够）
- `UnsupportedOperationException`(不支持的操作错误比如重复创建同一用户)

## finally 中的代码不会执行的情况

1. 执行 `finally` 之前，虚拟机被终止运行的话，`finally` 中的代码就不会被执行（比如在 `catch` 中执行了 `System.exit(1);` 直接终止了虚拟机）
2. 程序所在的线程死亡
3. 关闭 CPU

##  浅拷贝、深拷贝和引用拷贝

**浅拷贝**：浅拷贝会在 Heap（堆）上创建一个新的对象（区别于引用拷贝的一点）。如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址。

```java
public class Address implements Cloneable{
    private String name;
    // 省略构造函数、Getter&Setter方法
    @Override
    public Address clone() {
        try {
            return (Address) super.clone();
        } catch (CloneNotSupportedException e) {
            throw new AssertionError();
        }
    }
}

public class Person implements Cloneable {
    private Address address;
    // 省略构造函数、Getter&Setter方法
    @Override
    public Person clone() {
        try {
            Person person = (Person) super.clone();
            return person;
        } catch (CloneNotSupportedException e) {
            throw new AssertionError();
        }
    }
}
```

测试 ：

```java
Person person1 = new Person(new Address("武汉"));
Person person1Copy = person1.clone();
// true
System.out.println(person1.getAddress() == person1Copy.getAddress());
```

从输出结构就可以看出， `person1` 的克隆对象和 `person1` 使用的仍然是同一个 `Address` 对象。

---

**深拷贝** ：深拷贝会完全复制整个对象，包括这个对象所包含的内部对象。

```java
@Override
public Person clone() {
    try {
        Person person = (Person) super.clone();
        person.setAddress(person.getAddress().clone());
        return person;
    } catch (CloneNotSupportedException e) {
        throw new AssertionError();
    }
}
```

测试 ：

```java
Person person1 = new Person(new Address("武汉"));
Person person1Copy = person1.clone();
// false
System.out.println(person1.getAddress() == person1Copy.getAddress());
```

从输出结构就可以看出，虽然 `person1` 的克隆对象和 `person1` 包含的 `Address` 对象已经是不同的了。

---

**引用拷贝**：引用拷贝就是两个不同的引用指向同一个对象。

![浅拷贝、深拷贝、引用拷贝示意图](https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/github/javaguide/java/basis/shallow&deep-copy.png)

## final, finally, finalize的区别

final, finally, finalize的区别：

* final 用于声明属性,方法和类, 分别表示属性不可变, 方法不可覆盖, 类不可继承
* finally 是异常处理语句结构的一部分，表示总是执行
* finalize 是 Object 类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。JVM不保证此方法总被调用。

## 泛型

泛型的作用：

- Java 泛型（Generics） 是 JDK 5 中引入的一个新特性。使用泛型参数，可以增强代码的可读性以及稳定性。
- 编译器可以对泛型参数进行检测，并且通过泛型参数可以指定传入的对象类型。如果传入其他类型的对象就会报错。
- 原生 List 返回类型是 Object ，需要手动转换类型才能使用，使用泛型后编译器自动转换。

泛型的使用方式：

**泛型类、泛型接口、泛型方法**。

1. 泛型类：

```java
// 在实例化泛型类时，必须指定T的具体类型
public class Generic<T> {

    private T key;

    public Generic(T key) {
        this.key = key;
    }

    public T getKey(){
        return key;
    }
}
```

实例化泛型类：

```java
Generic<Integer> genericInteger = new Generic<Integer>(100);
```

2. 泛型接口：

```java
public interface Generator<T> {
    public T method();
}
```

实现泛型接口，不指定类型：

```java
class GeneratorImpl<T> implements Generator<T>{
    @Override
    public T method() {
        return null;
    }
}
```

实现泛型接口，指定类型：

```java
class GeneratorImpl<T> implements Generator<String>{
    @Override
    public String method() {
        return "hello";
    }
}
```

3. 泛型方法

```java
public static <E> void printArray(E[] inputArray){
	for ( E element : inputArray ){
		System.out.printf( "%s ", element );
	}
	System.out.println();
}
```

使用方式：

```java
// 创建不同类型数组： Integer, Double 和 Character
Integer[] intArray = { 1, 2, 3 };
String[] stringArray = { "Hello", "World" };
printArray(intArray);
printArray(stringArray);
```

>注意: `public static <E> void printArray(E[] inputArray)` 一般被称为静态泛型方法
>
>在 java 中，泛型只是一个占位符，必须在传递类型后才能使用。
>
>类在实例化时才能真正的传递类型参数，由于静态方法的加载先于类的实例化，也就是说类中的泛型还没有传递真正的类型参数，静态的方法的加载就已经完成了，所以静态泛型方法是没有办法使用类上声明的泛型的。只能使用自己声明的 `<E>`

项目中哪里用到了泛型？

- 自定义接口通用返回结果 `Result<T>` ，通过参数 `T` 可根据具体的返回类型，动态指定结果的数据类型
- 定义 `Excel` 处理类 `ExcelUtil<T>` ，用于动态指定 `Excel` 导出的数据类型
- 构建集合工具类（参考 `Collections` 中的 `sort` 和 `binarySearch` 方法）

## 序列化和反序列化

定义：

- **序列化**：将数据结构或对象转换成二进制字节流的过程
- **反序列化**：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程

常见应用场景：

- 对象在进行网络传输（比如远程方法调用 RPC 的时候）之前需要先被序列化，接收到序列化的对象之后需要再进行反序列化；
- 将对象存储到文件之前需要进行序列化，将对象从文件中读取出来需要进行反序列化；
- 将对象存储到数据库（如 Redis）之前需要用到序列化，将对象从缓存数据库中读取出来需要反序列化；
- 将对象存储到内存之前需要进行序列化，从内存中读取出来之后需要进行反序列化。

**序列化的主要目的是通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中**

使用 `transient` 关键字修饰不想进行序列化的变量：

- `transient` 关键字的作用是：阻止实例中那些用此关键字修饰的的变量序列化
- 当对象被反序列化时，被 `transient` 修饰的变量值不会被持久化和恢复
- `transient` 只能修饰变量，不能修饰类和方法
- `transient` 修饰的变量，在反序列化后变量值将会被置成类型的默认值。例如，如果是修饰 `int` 类型，那么反序列后结果就是 `0`。
- `static` 变量因为不属于任何对象(Object)，所以无论有没有 `transient` 关键字修饰，均不会被序列化

## BigDecimal

为什么浮点数 `float` 或 `double` 运算的时候会有精度丢失的风险呢？

> 计算机是二进制的，而且计算机在表示一个数字时，宽度是有限的，无限循环的小数存储在计算机时，只能被截断，所以就会导致小数精度发生损失的情况。这也就是解释了为什么浮点数没有办法用二进制精确表示。

**创建 BigDecimal**：

- 推荐使用 `BigDecimal(String val)` 构造方法或者  `BigDecimal.valueOf(double val)` 静态方法来创建对象。如果使用 `BigDecimal(double val)` 的话，仍然存在丢失精度的风险

**加减乘除**：

```java
BigDecimal a = new BigDecimal("1.0");
BigDecimal b = new BigDecimal("0.9");
System.out.println(a.add(b));// 1.9
System.out.println(a.subtract(b));// 0.1
System.out.println(a.multiply(b));// 0.90
System.out.println(a.divide(b));// 无法除尽，抛出 ArithmeticException 异常
System.out.println(a.divide(b, 2, RoundingMode.HALF_UP));// 1.11
```

在我们使用 `divide` 方法的时候尽量使用 3 个参数版本，并且`RoundingMode` 不要选择 `UNNECESSARY`，否则很可能会遇到 `ArithmeticException`（无法除尽出现无限循环小数的时候），其中 `scale` 表示要保留几位小数，`roundingMode` 代表保留规则。

```java
public BigDecimal divide(BigDecimal divisor, int scale, RoundingMode roundingMode) {
    return divide(divisor, scale, roundingMode.oldMode);
}
```

保留规则非常多，这里列举几种：

```java
public enum RoundingMode {
   // 2.5 -> 3 , 1.6 -> 2
   // -1.6 -> -2 , -2.5 -> -3
			 UP(BigDecimal.ROUND_UP),
   // 2.5 -> 2 , 1.6 -> 1
   // -1.6 -> -1 , -2.5 -> -2
			 DOWN(BigDecimal.ROUND_DOWN),
			 // 2.5 -> 3 , 1.6 -> 2
   // -1.6 -> -1 , -2.5 -> -2
			 CEILING(BigDecimal.ROUND_CEILING),
			 // 2.5 -> 2 , 1.6 -> 1
   // -1.6 -> -2 , -2.5 -> -3
			 FLOOR(BigDecimal.ROUND_FLOOR),
   	// 2.5 -> 3 , 1.6 -> 2
   // -1.6 -> -2 , -2.5 -> -3
			 HALF_UP(BigDecimal.ROUND_HALF_UP),
   //......
}
```

**大小比较**：

`a.compareTo(b)` : 返回 -1 表示 `a` 小于 `b`，0 表示 `a` 等于 `b` ， 1 表示 `a` 大于 `b`。

```java
BigDecimal a = new BigDecimal("1.0");
BigDecimal b = new BigDecimal("0.9");
System.out.println(a.compareTo(b));// 1
```

**保留几位小数**：

通过 `setScale`方法设置保留几位小数以及保留规则。保留规则有挺多种，不需要记，IDEA 会提示。

```java
BigDecimal m = new BigDecimal("1.255433");
BigDecimal n = m.setScale(3,RoundingMode.HALF_DOWN);
System.out.println(n);// 1.255
```

**等值比较**：

`BigDecimal` <u>使用 `equals()` 方法进行等值会出现问题</u>：

```java
BigDecimal a = new BigDecimal("1");
BigDecimal b = new BigDecimal("1.0");
System.out.println(a.equals(b));//false
```

这是因为 `equals()` 方法不仅仅会比较值的大小（value）还会比较精度（scale），而 `compareTo()` 方法比较的时候会忽略精度。

`compareTo()` 方法可以比较两个 `BigDecimal` 的值，如果相等就返回 0，如果第 1 个数比第 2 个数大则返回 1，反之返回-1。

```java
BigDecimal a = new BigDecimal("1");
BigDecimal b = new BigDecimal("1.0");
System.out.println(a.compareTo(b));//0
```

**BigDecimal 工具类分享**：

```java
import java.math.BigDecimal;
import java.math.RoundingMode;

/**
 * 简化BigDecimal计算的小工具类
 */
public class BigDecimalUtil {

    /**
     * 默认除法运算精度
     */
    private static final int DEF_DIV_SCALE = 10;

    private BigDecimalUtil() {
    }

    /**
     * 提供精确的加法运算。
     *
     * @param v1 被加数
     * @param v2 加数
     * @return 两个参数的和
     */
    public static double add(double v1, double v2) {
        BigDecimal b1 = BigDecimal.valueOf(v1);
        BigDecimal b2 = BigDecimal.valueOf(v2);
        return b1.add(b2).doubleValue();
    }

    /**
     * 提供精确的减法运算。
     *
     * @param v1 被减数
     * @param v2 减数
     * @return 两个参数的差
     */
    public static double subtract(double v1, double v2) {
        BigDecimal b1 = BigDecimal.valueOf(v1);
        BigDecimal b2 = BigDecimal.valueOf(v2);
        return b1.subtract(b2).doubleValue();
    }

    /**
     * 提供精确的乘法运算。
     *
     * @param v1 被乘数
     * @param v2 乘数
     * @return 两个参数的积
     */
    public static double multiply(double v1, double v2) {
        BigDecimal b1 = BigDecimal.valueOf(v1);
        BigDecimal b2 = BigDecimal.valueOf(v2);
        return b1.multiply(b2).doubleValue();
    }

    /**
     * 提供（相对）精确的除法运算，当发生除不尽的情况时，精确到
     * 小数点以后10位，以后的数字四舍五入。
     *
     * @param v1 被除数
     * @param v2 除数
     * @return 两个参数的商
     */
    public static double divide(double v1, double v2) {
        return divide(v1, v2, DEF_DIV_SCALE);
    }

    /**
     * 提供（相对）精确的除法运算。当发生除不尽的情况时，由scale参数指
     * 定精度，以后的数字四舍五入。
     *
     * @param v1    被除数
     * @param v2    除数
     * @param scale 表示表示需要精确到小数点以后几位。
     * @return 两个参数的商
     */
    public static double divide(double v1, double v2, int scale) {
        if (scale < 0) {
            throw new IllegalArgumentException(
                    "The scale must be a positive integer or zero");
        }
        BigDecimal b1 = BigDecimal.valueOf(v1);
        BigDecimal b2 = BigDecimal.valueOf(v2);
        return b1.divide(b2, scale, RoundingMode.HALF_UP).doubleValue();
    }

    /**
     * 提供精确的小数位四舍五入处理。
     *
     * @param v     需要四舍五入的数字
     * @param scale 小数点后保留几位
     * @return 四舍五入后的结果
     */
    public static double round(double v, int scale) {
        if (scale < 0) {
            throw new IllegalArgumentException(
                    "The scale must be a positive integer or zero");
        }
        BigDecimal b = BigDecimal.valueOf(v);
        BigDecimal one = new BigDecimal("1");
        return b.divide(one, scale, RoundingMode.HALF_UP).doubleValue();
    }

    /**
     * 提供精确的类型转换(Float)
     *
     * @param v 需要被转换的数字
     * @return 返回转换结果
     */
    public static float convertToFloat(double v) {
        BigDecimal b = new BigDecimal(v);
        return b.floatValue();
    }

    /**
     * 提供精确的类型转换(Int)不进行四舍五入
     *
     * @param v 需要被转换的数字
     * @return 返回转换结果
     */
    public static int convertsToInt(double v) {
        BigDecimal b = new BigDecimal(v);
        return b.intValue();
    }

    /**
     * 提供精确的类型转换(Long)
     *
     * @param v 需要被转换的数字
     * @return 返回转换结果
     */
    public static long convertsToLong(double v) {
        BigDecimal b = new BigDecimal(v);
        return b.longValue();
    }

    /**
     * 返回两个数中大的一个值
     *
     * @param v1 需要被对比的第一个数
     * @param v2 需要被对比的第二个数
     * @return 返回两个数中大的一个值
     */
    public static double returnMax(double v1, double v2) {
        BigDecimal b1 = new BigDecimal(v1);
        BigDecimal b2 = new BigDecimal(v2);
        return b1.max(b2).doubleValue();
    }

    /**
     * 返回两个数中小的一个值
     *
     * @param v1 需要被对比的第一个数
     * @param v2 需要被对比的第二个数
     * @return 返回两个数中小的一个值
     */
    public static double returnMin(double v1, double v2) {
        BigDecimal b1 = new BigDecimal(v1);
        BigDecimal b2 = new BigDecimal(v2);
        return b1.min(b2).doubleValue();
    }

    /**
     * 精确对比两个数字
     *
     * @param v1 需要被对比的第一个数
     * @param v2 需要被对比的第二个数
     * @return 如果两个数一样则返回0，如果第一个数比第二个数大则返回1，反之返回-1
     */
    public static int compareTo(double v1, double v2) {
        BigDecimal b1 = BigDecimal.valueOf(v1);
        BigDecimal b2 = BigDecimal.valueOf(v2);
        return b1.compareTo(b2);
    }

}
```

# 业务流程

> 数据库：JDBC 连接

> 前后端数据交互：RESTful API，映射实体类

业务流程：

1. 搜集需求
2. 筛选需求
3. 软件设计
4. 对应文档
5. 开发阶段：
	1. 交接需求
	2. 正常开发
	3. 测试
	4. 上线演练
	5. 上线
	6. 交付
	7. 验收
	8. 维护
